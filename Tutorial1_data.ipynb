{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf94fc1d-254b-48ee-9b85-983df35968d0",
   "metadata": {},
   "source": [
    "**Welcome to this Notebook!**  \n",
    "\n",
    "First, you need to clone this project in Google Colab.\n",
    "\n",
    "### Steps:  \n",
    "1. **Open Google Colab**  \n",
    "   - Go to https://colab.research.google.com \n",
    "\n",
    "2. **Open the Notebook**  \n",
    "   - Click on **File** → **Open Notebook**.  \n",
    "   - Select the **GitHub** tab and paste the following link into the field:  \n",
    "     https://github.com/WMallon/Mesa.git\n",
    "\n",
    "3. **Select the Notebook**  \n",
    "   - Choose **Tutorial1_data.ipynb** from the repository.  \n",
    "\n",
    "4. **Download the Data File**  \n",
    "   - Download the file to your PC from this link:  \n",
    "     https://drive.google.com/file/d/17WNyBegtgmuhhNm0N4Z6kbJj5i-8UI0j/view?usp=sharing\n",
    "\n",
    "5. **Upload the Data File**  \n",
    "   - Upload it as a ZIP file inside your Colab working folder.  \n",
    "\n",
    "6. **Unzip the File**  \n",
    "   - Use the following command to unzip the folder:\n",
    "   - !unzip sub-01.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7633d-cace-44ad-8c1e-2cd72045d023",
   "metadata": {},
   "source": [
    "What is a “nifti” file?\n",
    "Each MRI scanner manufacturer (e.g., Philips, Siemens, GE) uses its own proprietary data format. To facilitate compatibility across neuroimaging software, the Neuroimaging InFormatics Technology Initiative (NIfTI) introduced a standardized format called nifti. \n",
    "Most neuroimaging tools now support nifti, making it the preferred format for data processing.\n",
    "\n",
    "In these tutorial, you will primarily work with nifti files, also referred to as nifti images. These files typically have a .nii extension or a compressed version .nii.gz.\n",
    "\n",
    "Additionally, we will explore how to inspect and analyze nifti images in Python. The Nibabel library provides an excellent way to read and load nifti files and convert them into numpy arrays for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae934910-d823-4107-b020-55089393ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load some packages(libraries) we need for the analysis\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import nibabel as nib # common way of importing nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4823cbd0-6d92-4ef5-b3b9-fc0b033fdf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the structural dataset (T1)\n",
    "mri_file = 'sub-01/anat/sub-01_T1w.nii.gz'\n",
    "img = nib.load(mri_file) # here you have your data stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5ac3b9-41ad-482c-bf88-63b55644678f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the class type of the object img\n",
    "print(type(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42daf93e-e615-4a7f-936f-849779d13e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 3D size of the obejct img (T1 structural image)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de42a3-9b46-4b6d-ab02-da5014c69d8d",
   "metadata": {},
   "source": [
    "Every nifti file can be divided in three \"sections\":\n",
    "\n",
    "The header with metadata;\n",
    "The image data;\n",
    "The affine matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df78b197-5f2c-41d2-b5ae-4731e1bee8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let´s store the header in the variable hdr\n",
    "hdr = img.header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49fe84d-daba-47de-b549-e2b9edd4c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using this method you can get the voxel size (and optionally the sampling rate)\n",
    "hdr.get_zooms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c76538d-8192-467b-8818-4ded9fd2777f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By using this other method, you will get the units of the measurements (here: voxel size in millimeter and time in seconds):\n",
    "hdr.get_xyzt_units()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c63ca-20b3-4e09-adb4-ead7affe6e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is now time to load the second part of the nifti file, the imaging data!\n",
    "img_data = img.get_fdata()\n",
    "print(type(img_data))  # get the type of this object\n",
    "print(img_data.shape) #get the size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad399de-95c1-4f83-862e-c2207722b6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a 4x4x4 voxel patch  in the middle of the brain from the data and show the values\n",
    "# Original 3D size is (240, 256, 160)\n",
    "mid_vox = img_data[118:122, 126:130, 78:82]\n",
    "print(mid_vox)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29373b46-4239-4084-9cc0-ee3f16e95098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a single slice of the 3D volume, for example, the middle slice coronal\n",
    "mid_slice_x = img_data[119, :, :]\n",
    "print(mid_slice_x.shape) #print the size (256, 160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb09dd68-132c-4dcf-b6d8-a67d671b4f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use matplotlib to plot this slice as an image using the imshow function\n",
    "plt.imshow(mid_slice_x, cmap='gray', origin='lower')\n",
    "plt.xlabel('First axis')\n",
    "plt.ylabel('Second axis')\n",
    "plt.colorbar(label='Signal intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85a69e-1c64-4012-b7ab-12d4402ee6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (10 Minutes)\n",
    "# Extract a single slice of the 3D volume, for example the middle slice axial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f94ba97-aad3-453c-9a01-734ca68548e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (5 Minutes)\n",
    "# Extract a single slice of the 3D volume, for example the middle slice sagittal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454d40c3-1037-4148-a5b8-6ac06257488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: (10 Minutes)\n",
    "# Load the functional file and print its size and the measurement units.\n",
    "# Is it the same as the structural?\n",
    "# What can you say about it?\n",
    "# How long did the experiment last?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866adff7-1194-4990-a30a-f713acb436ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the second part of the functional file, the imaging data!\n",
    "f_img_data = f_img.get_fdata()\n",
    "print(f_img_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9b4b7f-f167-4d05-9cd6-1dedb9f2f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the slice #26 at time = 10s (t = 10)\n",
    "mid_slice_x_fmri = f_img_data[26, :, :, 5] \n",
    "# TO-DO\n",
    "# Why 5?\n",
    "\n",
    "print(\"Shape of slice: %s\" % (mid_slice_x_fmri.shape,))\n",
    "\n",
    "plt.imshow(mid_slice_x_fmri.T, cmap='gray', origin='lower')\n",
    "plt.xlabel('First axis')\n",
    "plt.ylabel('Second axis')\n",
    "plt.colorbar(label='Signal intensity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc2f8fb-4f94-4b6c-9cbe-c0a7db9299ad",
   "metadata": {},
   "source": [
    "Alternatively, we can analyze fMRI data through the time. Instead of focusing on spatial patterns, we can examine how the signal intensity of a single voxel changes over time. This involves extracting the time series of a specific voxel and plotting its intensity fluctuations over the course of the scan.\n",
    "\n",
    "To begin, let’s retrieve the time series data for a particular voxel—for instance, the one located at the center of all spatial dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4a00a-14ca-47e4-ad62-9cd6b1ae34c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_vox_ts = f_img_data[31, 31, 21, :]  # note the \":\", saying: give me ALL the timepoints\n",
    "print(\"Voxel timeseries shape: %s\" % (mid_vox_ts.shape,))\n",
    "# TO-DO\n",
    "# Why its size corresponds to 204?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf321330-5ed4-444f-907b-76dd35441989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show the time course of the same voxel (mid_vox_ts). This is the BOLD signal!\n",
    "plt.figure(figsize=(18, 3))\n",
    "plt.plot(mid_vox_ts, 'o-', ms=2)\n",
    "plt.xlim(-1, mid_vox_ts.size)\n",
    "plt.ylabel('Signal intensity', fontsize=15)\n",
    "plt.xlabel('Time (in # of volumes)', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c701f-24f3-4849-a1f1-1a15b9264e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (20 Minutes)\n",
    "# Approximate the location of the somatosensory cortex (left or right) and extract the time course of this Voxel\n",
    "# Help: you could use MRICroGL to guess the position of the Somatosensory Cortex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0725e8e-7ef9-4672-9564-1c1db92f90b8",
   "metadata": {},
   "source": [
    "Understanding the Affine Matrix\n",
    "Every nifti file contains not just the imaging data and metadata but also an affine matrix. This matrix serves as a crucial link between the voxel-based image coordinates and real-world spatial locations. If this concept seems abstract at first, let’s explore a scenario where the affine matrix plays a key role.\n",
    "\n",
    "Imagine a colleague hands you a nifti file, but you have no prior information about its contents—it could be a brain scan, or it could be something entirely different. To get a sense of what’s inside, you decide to visualize three slices, each taken from a different axis. Specifically, you select slice 120 along the first axis (noting that Python uses zero-based indexing, so this corresponds to index 119), slice 128 from the second axis, and another slice 80 from the third axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cfe062-e4fb-4e46-bb81-5bdd9640e722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the first voxel axis represents the coronal dimension (anterior ←→ posterior)\n",
    "# the second voxel axis represents the represents the axial dimension (inferior ←→ superior) \n",
    "# the third one represents the sagittal dimension (left ←→ right)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(img_data[89, :, :], origin='lower', cmap='gray')\n",
    "ax[0].set_xlabel('Second dim voxel coords.', fontsize=12)\n",
    "ax[0].set_ylabel('Third dim voxel coords', fontsize=12)\n",
    "ax[0].set_title('First dimension, slice nr. 90', fontsize=15)\n",
    "\n",
    "ax[1].imshow(img_data[:, 99, :], origin='lower', cmap='gray')\n",
    "ax[1].set_xlabel('First dim voxel coords.', fontsize=12)\n",
    "ax[1].set_ylabel('Third dim voxel coords', fontsize=12)\n",
    "ax[1].set_title('Second dimension, slice nr. 100', fontsize=15)\n",
    "\n",
    "ax[2].imshow(img_data[:, :, 99].T, origin='lower', cmap='gray')\n",
    "ax[2].set_xlabel('First dim voxel coords.', fontsize=12)\n",
    "ax[2].set_ylabel('Second dim voxel coords', fontsize=12)\n",
    "ax[2].set_title('Third dimension, slice nr. 100', fontsize=15)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a172c589-3d04-4d72-9957-56ddceacef2d",
   "metadata": {},
   "source": [
    "Problem: To accurately interpret voxel data, we need a method to determine spatial orientation—identifying left from right, as well as anterior/posterior and inferior/superior within our voxel space. This is where the affine matrix comes into play! It acts as a reference, ensuring that what we perceive as \"left\" in voxel space actually corresponds to \"left\" in real-world coordinates.\n",
    "\n",
    "In this context, \"real-world space\" refers to the position of voxels in millimeters relative to the scanner’s isocenter. \n",
    "The isocenter serves as the origin of this coordinate system.\n",
    "\n",
    "By convention, Nibabel’s Nifti1Image format assumes a specific axis orientation:\n",
    "\n",
    "The first axis extends from left to right,\n",
    "The second axis moves from posterior to anterior,\n",
    "The third axis runs from inferior to superior.\n",
    "This standard is often abbreviated as RAS+, meaning that positions to the Right, Anterior, and Superior of the isocenter have positive (+) coordinates, while positions to the Left, Posterior, and Inferior are assigned negative (-) values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4a14ae-6791-46c9-a67c-fa6d375b8423",
   "metadata": {},
   "source": [
    "It turns out you only need a simple matrix operation: for a set of voxel coordinates (i,j,k) appended with a single 1, and an\n",
    " affine matrix A, you can get the real word coordinates (in RAS+) by the dot product (matrix multiplication) of A and (i,j,k,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c575455c-ec41-4158-bb63-e44e1443eae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our image’s affine should be a 4x4  matrix --> [x y z 1] = A[i,j,k,1]\n",
    "np.set_printoptions(suppress=True, precision=3)  # suppresses scientific notation\n",
    "A = img.affine\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9c4f17-b37c-4a4c-8762-bda886d4aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, imagine you want to determine whether the sagittal slice shown in the leftmost plot of the previous figure \n",
    "# corresponds to the anterior or posterior side of the brain. To do this, we need to find the real-world coordinate \n",
    "# that corresponds to a given voxel coordinate (i = 89). \n",
    "# Let’s select the middle voxel index for the other two dimensions (j = 127, k = 79)\n",
    "\n",
    "import matplotlib.patches as patches\n",
    "fig, ax = plt.subplots(ncols=3, figsize=(15, 5))\n",
    "\n",
    "ax[0].imshow(img_data[89, :, :].T, origin='lower', cmap='gray')\n",
    "ax[0].set_xlabel('Second dim voxel coords.', fontsize=12)\n",
    "ax[0].set_ylabel('Third dim voxel coords', fontsize=12)\n",
    "ax[0].set_title('First dimension, slice nr. 90', fontsize=15)\n",
    "rect = patches.Rectangle((127, 79), 3, 3, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[0].add_patch(rect)\n",
    "\n",
    "ax[1].imshow(img_data[:, 127, :].T, origin='lower', cmap='gray')\n",
    "ax[1].set_xlabel('First dim voxel coords.', fontsize=12)\n",
    "ax[1].set_ylabel('Third dim voxel coords', fontsize=12)\n",
    "ax[1].set_title('Second dimension, slice nr. 128', fontsize=15)\n",
    "rect = patches.Rectangle((89, 79), 3, 3, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[1].add_patch(rect)\n",
    "\n",
    "ax[2].imshow(img_data[:, :, 79].T, origin='lower', cmap='gray')\n",
    "ax[2].set_xlabel('First dim voxel coords.', fontsize=12)\n",
    "ax[2].set_ylabel('Second dim voxel coords', fontsize=12)\n",
    "ax[2].set_title('Third dimension, slice nr. 80', fontsize=15)\n",
    "rect = patches.Rectangle((89, 127), 3, 3, linewidth=2, edgecolor='r', facecolor='none')\n",
    "ax[2].add_patch(rect)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1233b38-f6d8-479c-bf17-e28d8ad4afe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz1 = A @ np.array([89, 127, 79, 1])\n",
    "print(xyz1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4939be6c-0871-4b0d-ad60-deaed2d0b3b4",
   "metadata": {},
   "source": [
    "Here we see that the real world coordinate is -9.266, which means that this coordinate is 9.266 millimeters to the left (-) of the isocenter (RAS+)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
