{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c55005f-a2ee-4e3e-a36f-472d54a04157",
   "metadata": {},
   "source": [
    "**Welcome to this Notebook!**  \n",
    "\n",
    "First, you need to clone this project in Google Colab.\n",
    "\n",
    "### Steps:  \n",
    "1. **Open Google Colab**  \n",
    "   - Go to https://colab.research.google.com \n",
    "\n",
    "2. **Open the Notebook**  \n",
    "   - Click on **File** â†’ **Open Notebook**.  \n",
    "   - Select the **GitHub** tab and paste the following link into the field:  \n",
    "     https://github.com/WMallon/Mesa.git\n",
    "\n",
    "3. **Select the Notebook**  \n",
    "   - Choose **Tutorial2_glm.ipynb** from the repository.  \n",
    "\n",
    "4. **Download the Data File**  \n",
    "   - Download the file to your PC from this link:  \n",
    "     https://drive.google.com/file/d/17WNyBegtgmuhhNm0N4Z6kbJj5i-8UI0j/view?usp=sharing\n",
    "\n",
    "5. **Upload the Data File**  \n",
    "   - Upload it as a ZIP file inside your Colab working folder.  \n",
    "\n",
    "6. **Unzip the File**  \n",
    "   - Use the following command to unzip the folder:\n",
    "   - !unzip sub-01.zip\n",
    "     \n",
    "7. **Install the nilearn libraries**  \n",
    "   - Use the following command to do it:\n",
    "   - pip install nilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cbeea2-f0c0-4bd1-a2a5-e14165925106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries used during the computation\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib # nibabel library\n",
    "import pandas as pd # panda library\n",
    "import matplotlib as mpl # plotting library\n",
    "import matplotlib.pyplot as plt # plotting library\n",
    "# Import Nilearn library\n",
    "from nilearn.glm import first_level\n",
    "from nilearn.plotting import plot_design_matrix, plot_contrast_matrix, plot_stat_map\n",
    "from nilearn.glm.first_level import FirstLevelModel, make_first_level_design_matrix\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.image import mean_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec3032b-1c61-4d38-8561-d927ab6788b9",
   "metadata": {},
   "source": [
    "---\n",
    "### **The Hemodynamic Response Function (HRF) in fMRI**  \n",
    "\n",
    "The **Hemodynamic Response Function (HRF)** is a mathematical model that describes how neural activity leads to changes in **blood oxygenation** and **blood flow**, which can be measured using functional MRI (**fMRI**). The HRF represents the **time course of the blood-oxygen-level-dependent (BOLD) signal** following a brief burst of neural activity.  \n",
    "\n",
    "---\n",
    "\n",
    "### **1. The Process Behind the HRF**  \n",
    "When a brain region becomes active:  \n",
    "1. **Neurons fire**, consuming oxygen.  \n",
    "2. **Local blood flow increases**, delivering more oxygenated blood than is consumed.  \n",
    "3. The excess oxygenated blood changes the **ratio of oxygenated to deoxygenated hemoglobin**.  \n",
    "4. This change alters the **BOLD signal**, which is what fMRI detects.  \n",
    "\n",
    "The HRF characterizes this entire process, typically showing three main phases:  \n",
    "\n",
    "| Phase | Description |\n",
    "|-------|------------|\n",
    "| **Initial Dip** (optional) | A brief **drop in BOLD signal** due to immediate oxygen consumption. |\n",
    "| **Peak Response** (~4â€“6s) | A **rise in BOLD signal** as blood flow increases. |\n",
    "| **Post-Stimulus Undershoot** (~10â€“30s) | A slight **drop below baseline** before returning to normal. |\n",
    "\n",
    "--- \n",
    "\n",
    "Different fMRI software (like **SPM**, **FSL**, or **AFNI**) may use slightly different HRF models.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why is the HRF Important in fMRI Analysis?**  \n",
    "âœ… **Models the delayed nature of the BOLD response** (~4â€“6s lag).  \n",
    "âœ… Helps in **designing experimental paradigms** (e.g., adjusting stimulus timing).  \n",
    "âœ… Used in **statistical analyses** (General Linear Model, GLM) to detect brain activation.  \n",
    "âœ… Essential for **deconvolution** methods in event-related fMRI studies.  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. Variability in the HRF**  \n",
    "The HRF is not identical across all brain regions or individuals. It can vary due to:  \n",
    "- **Age & Health** (e.g., vascular differences).  \n",
    "- **Brain Region** (e.g., visual cortex vs. prefrontal cortex).  \n",
    "- **Stimulus Duration & Type** (e.g., brief vs. sustained stimuli).  \n",
    "\n",
    "For this reason, some studies use **individualized HRFs** instead of the standard model.\n",
    "\n",
    "---\n",
    "OpenAI. ChatGPT (Feb 11 version). 2025. https://chat.openai.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045f3eb-6690-4f52-a46c-cbf7f60dcd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (5 Minutes)\n",
    "# Search for the HRF on Google and examine its temporal behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b596cbae-cbb5-4a95-8749-19c210a83075",
   "metadata": {},
   "source": [
    "---\n",
    "The **Glover** and **SPM HRF (Hemodynamic Response Function)** are two commonly used models for describing the blood-oxygen-level-dependent (**BOLD**) response in functional MRI (**fMRI**). While they serve a similar purposeâ€”modeling how neural activity leads to measurable changes in blood flowâ€”they have key differences in their formulation and characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Glover HRF**\n",
    "- Proposed by **Glover (1999)** as an empirical model for the hemodynamic response.\n",
    "- Defined as a **difference of two gamma functions**:  \n",
    "  - A **positive** gamma function modeling the main **BOLD response (oxygenated blood flow increase)**.\n",
    "  - A **negative** gamma function modeling the **undershoot** (post-activation dip).\n",
    "- More **data-driven** and optimized for empirical fits to fMRI data.\n",
    "\n",
    "### **2. SPM HRF**\n",
    "- The **Statistical Parametric Mapping (SPM)** HRF is the default model used in **SPM (a widely used fMRI analysis toolbox)**.\n",
    "- It is also based on a **double gamma function** but is more standardized.\n",
    "- The parameters were optimized based on **averaged BOLD responses** from experimental data.\n",
    "\n",
    "### **Key Differences**\n",
    "| Feature         | Glover HRF | SPM HRF |\n",
    "|---------------|-----------|---------|\n",
    "| **Model Type** | Empirical, fitted to data | Standardized function used in SPM |\n",
    "| **Flexibility** | More flexible for individual fits | Fixed parameters, good for group studies |\n",
    "| **Post-Stimulus Undershoot** | Explicitly modeled | Included but less flexible |\n",
    "| **Use Case** | Custom modeling and optimizing HRF for specific datasets | Standard fMRI analyses, GLM-based methods |\n",
    "\n",
    "### **Which One to Use?**\n",
    "- If you are using **SPM or FSL**, the **SPM HRF** is the standard choice.\n",
    "- If you want a more **customizable HRF** that can better fit individual differences, **Glover HRF** is a better option.\n",
    "\n",
    "Would you like a visual comparison of their shapes? ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d77425-2495-4b20-b052-24478e6bcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show difference between Glover and SPM HRF\n",
    "time_length = 30\n",
    "\n",
    "glover_timecourse = first_level.glover_hrf(1, oversampling=50, time_length=time_length)\n",
    "spm_timecourse = first_level.spm_hrf(1, oversampling=50, time_length=time_length)\n",
    "\n",
    "sample_times = np.linspace(0, time_length, num=len(glover_timecourse))\n",
    "\n",
    "plt.plot(sample_times, glover_timecourse, label=\"Glover\")\n",
    "plt.plot(sample_times, spm_timecourse, label=\"SPM\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (AU)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154acf03-fcaa-4a87-9f0f-3c0951dee6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to compute the Regressors\n",
    "\n",
    "#Define some functions\n",
    "def generate_stim(onset, amplitude, duration, hrf_model, maxtime=30):\n",
    "    # Generate signal with specified duration and onset\n",
    "    frame_times = np.linspace(0, maxtime, 601)\n",
    "    exp_condition = np.array((onset, duration, amplitude)).reshape(3, 1)\n",
    "    stim = np.zeros_like(frame_times)\n",
    "    stim[(frame_times > onset) * (frame_times <= onset + duration)] = amplitude\n",
    "\n",
    "    signal, name = first_level.compute_regressor(\n",
    "        exp_condition, hrf_model, frame_times, con_id=\"main\", oversampling=16\n",
    "    )\n",
    "\n",
    "    return frame_times, stim, signal\n",
    "\n",
    "\n",
    "def plot_regressor(onset, amplitude, duration, hrf_model):\n",
    "    frame_times, stim, signal = generate_stim(onset, amplitude, duration, hrf_model)\n",
    "    plt.fill(frame_times, stim, \"k\", alpha=0.5, label=\"stimulus\")\n",
    "    plt.plot(frame_times, signal.T[0], label=\"Regressor\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Amplitude (AU)\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.title(hrf_model)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Generate an event of 1 second duration starting at time 0\n",
    "# You could use one of the following HRFs:\n",
    "# spm, spm + derivative, spm + derivative + dispersion, fir, \n",
    "# glover, glover + derivative, glover + derivative + dispersion\n",
    "\n",
    "hrf_model = \"spm\"\n",
    "onset, amplitude, duration = 0.0, 1.0, 1.0\n",
    "plot_regressor(onset, amplitude, duration, hrf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dabed06-faff-4d4b-a1da-3de3c826965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (5 Minutes)\n",
    "# Now change the duration of the stimulus up to 20 s and look for the differences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9bcffe-daad-4b33-b05a-ccff55ea111b",
   "metadata": {},
   "source": [
    "In Statistical Parametric Mapping (SPM), time and dispersion derivatives are used in fMRI analysis to improve the modeling of the hemodynamic response function (HRF). Their main purpose is to account for variations in the timing and shape of the HRF across different brain regions and subjects.\n",
    "\n",
    "1. Time Derivative\n",
    "Captures small variations in the onset of the hemodynamic response.\n",
    "Useful when there is temporal jitter (slight shifts in timing) between stimulus presentation and the actual BOLD response.\n",
    "Mathematically, it is the first derivative of the canonical HRF.\n",
    "Improves model fit without increasing the number of regressors too much.\n",
    "\n",
    "3. Dispersion Derivative\n",
    "Captures variations in the duration or width of the HRF.\n",
    "Useful when the shape of the HRF deviates from the canonical model due to vascular differences or neural adaptation.\n",
    "Mathematically, it is the second derivative of the canonical HRF.\n",
    "Helps account for differences in BOLD response duration across brain regions.\n",
    "\n",
    "\n",
    "When to Use Them?\n",
    "If you suspect variability in HRF timing, include the time derivative.\n",
    "If you expect variations in HRF shape, include both time and dispersion derivatives.\n",
    "They allow for a more flexible and robust GLM analysis in SPM, reducing misalignment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2686f6-e05e-4903-a6e0-408828a97b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO\n",
    "# Compare the different HRFs in SPM by overlaying them\n",
    "# If you need more information, check out this webpage https://nilearn.github.io/dev/modules/glm.html\n",
    "\n",
    "\n",
    "spm_time = first_level.spm_time_derivative(1, oversampling=50, time_length=time_length)\n",
    "spm_dispers = first_level.spm_dispersion_derivative(1, oversampling=50, time_length=time_length)\n",
    "spm_canonical = first_level.spm_hrf(1, oversampling=50, time_length=time_length)\n",
    "\n",
    "sample_times = np.linspace(0, time_length, num=len(glover_timecourse))\n",
    "plt.plot(sample_times, spm_timecourse, label=\"SPM\")\n",
    "plt.plot(sample_times, spm_time, label=\"Time Derivative\")\n",
    "plt.plot(sample_times, spm_dispers, label=\"Dispersion Derivative\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Amplitude (AU)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c5956d-f977-490b-9586-e18a051f0c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we plot multiple durations (1,3,5 s...) to see how the resulting regressor varies\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(7, 7))\n",
    "cmap = mpl.cm.viridis\n",
    "norm = mpl.colors.Normalize(vmin=0, vmax=40)\n",
    "\n",
    "for n in [1, 3, 5, 10, 15, 20, 25, 30, 35]:\n",
    "    frame_times, stim, signal = generate_stim(\n",
    "        onset, amplitude, n, hrf_model, maxtime=50\n",
    "    )\n",
    "    axes.plot(frame_times, signal.T[0], label=\"Regressor\", c=cmap(norm(n)))\n",
    "\n",
    "axes.set_xlabel(\"Time (s)\")\n",
    "axes.set_ylabel(\"Amplitude (AU)\")\n",
    "plt.colorbar(mpl.cm.ScalarMappable(norm=norm, cmap=cmap), ax=axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13630c8e-bf91-4170-b31e-3e9816b60f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (5 Minutes)\n",
    "# What conclusion can we draw about the HRF duration after examining this plot?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a5b4050-d9a7-428e-80b9-afbea2e3d51c",
   "metadata": {},
   "source": [
    "It is time to plot the HRF of a real finger tapping experiment.\n",
    "\n",
    "A finger-tapping experiment is a commonly used motor task in neuroscience and cognitive research, particularly in functional MRI (fMRI) and EEG studies, to investigate motor control, brain activation, and neuroplasticity.\n",
    "\n",
    "Overview of the Experiment:\n",
    "Participants are instructed to tap their fingers in a specific sequence or rhythm (e.g., alternating between index and middle fingers).\n",
    "The task is often performed under different conditions: self-paced, externally cued (e.g., metronome-paced), or involving different hand movements.\n",
    "Brain activity is recorded, typically using fMRI to assess activation in motor-related regions (e.g., the primary motor cortex (M1), premotor cortex, supplementary motor area (SMA), and cerebellum).\n",
    "Purpose:\n",
    "To study motor system function and connectivity.\n",
    "To investigate plasticity in patients with neurological disorders (e.g., Parkinsonâ€™s disease, stroke recovery).\n",
    "To assess brain lateralization in motor tasks.\n",
    "\n",
    "\n",
    "Scientific Reference:\n",
    "Biswal, B., Yetkin, F. Z., Haughton, V. M., & Hyde, J. S. (1995). Functional connectivity in the motor cortex of resting human brain using echo-planar MRI. Magnetic Resonance in Medicine, 34(4), 537-541. https://doi.org/10.1002/mrm.1910340409\n",
    "\n",
    "This study is significant because it introduced resting-state functional connectivity, using a finger-tapping task to demonstrate correlations between different motor regions.\n",
    "\n",
    "You can find a picture of the FT experiment inside the sub-01 folder\n",
    "\n",
    "Our experiment lasts 400 s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da716d-590c-4720-bda0-78f91b81fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (20 Minutes)\n",
    "# Plot the hrf of the finger tapping right, left and baseline separately or superimposed\n",
    "# Consider the duration of the stimulus\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a655100-0cb0-4952-a744-7d6b7a2ba5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some Imports\n",
    "from nilearn.glm.first_level.hemodynamic_models import spm_hrf\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259907df-5d5a-4d77-8340-f9a263e6fa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will demonstrate the FT Block vs Event-Related Design\n",
    "\n",
    "# Define the random generator\n",
    "np.random.seed(2)\n",
    "\n",
    "N = 400 # Total Experiment length in s\n",
    "\n",
    "# Define the SPM Canonical HRF\n",
    "dg_hrf = spm_hrf(t_r=2, oversampling=1) # TR = 2\n",
    "\n",
    "# Definition of the Regressors in the Block Design\n",
    "# Finger tapping Right\n",
    "blocked_pred1_onsets = list(range(20, 40)) + list(range(100, 120)) + list(range(180, 200)) + list(range(260, 280)) \\\n",
    "+ list(range(340, 360))   \n",
    "\n",
    "# Finger tapping Left\n",
    "blocked_pred2_onsets = list(range(60, 80)) + list(range(140, 160)) + list(range(220, 240)) + list(range(300, 320)) \\\n",
    "+ list(range(380, 400))\n",
    "\n",
    "# Finger tapping Baseline\n",
    "blocked_pred3_onsets = list(range(0, 20)) + list(range(40, 60)) + list(range(80, 100)) + list(range(120, 140))\\\n",
    "+ list(range(160, 180)) + list(range(200, 220)) + list(range(240, 260)) + list(range(280, 300)) \\\n",
    "+ list(range(320, 340)) + list(range(360, 380))   #Baseline\n",
    "\n",
    "# Fill the regressors with ones (according to the experiment timing)\n",
    "N_stim = len(blocked_pred1_onsets)\n",
    "blocked_pred1, blocked_pred2, blocked_pred3 = np.zeros(N), np.zeros(N), np.zeros(N)\n",
    "blocked_pred1[blocked_pred1_onsets] = 1\n",
    "blocked_pred2[blocked_pred2_onsets] = 1\n",
    "blocked_pred3[blocked_pred3_onsets] = 1\n",
    "\n",
    "# Define the Design Matrix X (by convolving the Regressors with the Canonical HRF)\n",
    "icept = np.ones((N, 1))\n",
    "X_blocked = np.hstack((\n",
    "    np.convolve(blocked_pred1, dg_hrf)[:N, np.newaxis],\n",
    "    np.convolve(blocked_pred2, dg_hrf)[:N, np.newaxis],\n",
    "    np.convolve(blocked_pred3, dg_hrf)[:N, np.newaxis],\n",
    "     icept\n",
    "))\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Blocked events (red = right, blue = left) without baseline (for clarity)\", fontsize=20)\n",
    "plt.xlim(0, N)\n",
    "plt.axhline(0, c='tab:blue')\n",
    "plt.grid()\n",
    "\n",
    "for onset in blocked_pred1_onsets:\n",
    "    plt.plot((onset, onset), (0, 1), c='tab:red') # Right\n",
    "\n",
    "for onset in blocked_pred2_onsets:\n",
    "    plt.plot((onset, onset), (0, 1), c='tab:blue') # Left\n",
    "    \n",
    "''' # We avoid plotting also the baseline         \n",
    "for onset in blocked_pred3_onsets:\n",
    "    plt.plot((onset, onset), (0, 1), c='tab:green') # Baseline\n",
    "'''\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.xlim(0, N)\n",
    "plt.title(\"Convolved predictors (BLOCKED) with baseline (green)\", fontsize=20)\n",
    "plt.ylim(-1, 2)\n",
    "plt.plot(X_blocked[:, 0], c='tab:red')\n",
    "plt.plot(X_blocked[:, 1], c='tab:blue')\n",
    "plt.plot(X_blocked[:, 2], c='tab:green')\n",
    "plt.grid()\n",
    "plt.xlabel(\"Time (volumes)\", fontsize=15)\n",
    "\n",
    "# Event-Related Design code------------------------------------------------\n",
    "er_stims = np.arange(N)\n",
    "er_pred1_onsets = np.random.choice(er_stims, N_stim, replace=False)\n",
    "er_stims_new = np.array([o for o in er_stims if o not in er_pred1_onsets])\n",
    "er_pred2_onsets = np.random.choice(er_stims_new, N_stim, replace=False)\n",
    "er_pred1, er_pred2 = np.zeros(N), np.zeros(N)\n",
    "er_pred1[er_pred1_onsets] = 1\n",
    "er_pred2[er_pred2_onsets] = 1\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.xlim(0, N)\n",
    "plt.title(\"Event onsets (EVENT-RELATED)\", fontsize=20)\n",
    "plt.axhline(0, c='tab:blue')\n",
    "plt.grid()\n",
    "\n",
    "for onset in er_pred1_onsets:\n",
    "    plt.plot((onset, onset), (0, 1), c='tab:blue')\n",
    "\n",
    "for onset in er_pred2_onsets:\n",
    "    plt.plot((onset, onset), (0, 1), c='tab:orange')\n",
    "\n",
    "X_er = np.hstack((\n",
    "    icept,\n",
    "    np.convolve(er_pred1, dg_hrf)[:N, np.newaxis],\n",
    "    np.convolve(er_pred2, dg_hrf)[:N, np.newaxis]\n",
    "))\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "\n",
    "plt.title(\"Convolved predictors (EVENT-RELATED)\", fontsize=20)\n",
    "plt.ylim(-1, 2)\n",
    "plt.plot(X_er[:, 1], c='tab:blue')\n",
    "plt.plot(X_er[:, 2], c='tab:orange')\n",
    "plt.axhline(0, ls='--', c='k')\n",
    "plt.xlim(0, N)\n",
    "plt.grid()\n",
    "plt.xlabel(\"Time (volumes)\", fontsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d900201-174a-4fef-a0b5-dcd7c13c5c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It is time to calculate the correlation and to compare them (Block vs Event)\n",
    "corr_blocked = pearsonr(X_blocked[:, 0], X_blocked[:, 1])\n",
    "corr_er = pearsonr(X_er[:, 1], X_er[:, 2])\n",
    "print(\"Correlation blocked: %.3f. Correlation event-related: %.3f\" % (corr_blocked[0], corr_er[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78bf7a-a472-4f48-b8cf-b858b63e52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (10 Minutes)\n",
    "# Calculate the correlation between the baseline and the left/right regressors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac2ed87-b2e8-4f6c-9fbc-02b409d0358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (5 Minutes)\n",
    "# Describe the design efficiency?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f3281-3de7-42a5-82d1-c25c3479fb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrast R > 0\n",
    "cvec = np.array([1, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e8a60-cd72-477f-a548-c74d398d00cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficiency = 1.0 / c @ inv(X.T @ X) @ c.T\n",
    "eff = 1.0 / cvec.dot(np.linalg.inv(X_blocked.T.dot(X_blocked))).dot(cvec.T)\n",
    "print(\"Efficiency: %.3f\" % (eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d0813b-d11d-4f29-8ba3-046b09e677b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO (20 Minutes)\n",
    "# Calculate the Efficiency of the ER Design Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d0b041-ec4c-48bf-a029-a4aa641d1353",
   "metadata": {},
   "source": [
    "---\n",
    "In **SPM (Statistical Parametric Mapping)**, the **`rp_` file** contains **realignment parameters** for an fMRI session. These parameters are crucial for **motion correction** in fMRI preprocessing.  \n",
    "\n",
    "### **1. What is the `rp_` file?**  \n",
    "- The filename follows this pattern:  \n",
    "  **`rp_<functional_image>.txt`**  \n",
    "  - Example: `rp_func_scan1.txt`  \n",
    "- It is a **text file** generated during **motion correction (realignment)** in SPM.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. What Data Does It Contain?**  \n",
    "The `rp_` file contains a **6-column matrix**, where each row corresponds to a scan (volume) in the fMRI time series:  \n",
    "\n",
    "| Column | Parameter | Description |\n",
    "|---------|------------|----------------|\n",
    "| 1 | X | Translation (Left/Right) |\n",
    "| 2 | Y | Translation (Forward/Backward) |\n",
    "| 3 | Z | Translation (Up/Down) |\n",
    "| 4 | Pitch | Rotation around **X-axis** |\n",
    "| 5 | Roll | Rotation around **Y-axis** |\n",
    "| 6 | Yaw | Rotation around **Z-axis** |\n",
    "\n",
    "All values are in **millimeters (mm) for translations** and **radians for rotations**.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Why is the `rp_` File Important?**  \n",
    "âœ… **Motion Correction** â€“ Used to correct for participant head movements.  \n",
    "âœ… **Confound Regressors** â€“ Motion parameters can be added to the **GLM** (General Linear Model) as nuisance regressors to reduce motion-related artifacts.  \n",
    "âœ… **Quality Control** â€“ Helps check if excessive motion (>1â€“2mm) might affect results.  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. How to Use the `rp_` File?**  \n",
    "- **Include in GLM Analysis**  \n",
    "  - Motion parameters can be added as **covariates** in the first-level analysis to reduce motion-related confounds.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ad810b-443e-4b9a-b633-a7c03d64f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we are going to use the real dataset for the Finger Tapping Experiment\n",
    "# Inspect the Rigid Body Motion file (rp_**)\n",
    "\n",
    "# Load the motion file\n",
    "rigib_body_file = 'sub-01/func/rp_sub-01_task-ft_run-1_bold.txt'\n",
    "motion_params = np.loadtxt(rigib_body_file)\n",
    "rotation_params = motion_params[:, :3]\n",
    "translation_params = motion_params[:, 3:]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Rotation', fontsize=25)\n",
    "plt.plot(rotation_params)\n",
    "plt.xlim(0, motion_params.shape[0])\n",
    "plt.legend(['x', 'y', 'z'], fontsize=15)\n",
    "plt.ylabel('Rotation in radians', fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Translation', fontsize=25)\n",
    "plt.plot(translation_params)\n",
    "plt.legend(['x', 'y', 'z'], fontsize=15)\n",
    "plt.ylabel('Translation in mm', fontsize=15)\n",
    "plt.xlim(0, motion_params.shape[0])\n",
    "plt.xlabel('Time (TR)', fontsize=15)\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587374a9-4f31-4796-a78f-76f11494de36",
   "metadata": {},
   "source": [
    "---\n",
    "### **The Design Matrix in SPM?**  \n",
    "\n",
    "In **SPM (Statistical Parametric Mapping)**, the **design matrix** is a fundamental part of the **General Linear Model (GLM)** used for analyzing fMRI data. It defines how experimental conditions, confounds, and other factors are modeled in the statistical analysis of brain activity.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Purpose of the Design Matrix**  \n",
    "The design matrix:  \n",
    "âœ… **Models the experimental conditions** (e.g., task vs. rest, stimulus onsets).  \n",
    "âœ… **Accounts for confounds** (e.g., motion, physiological noise).  \n",
    "âœ… **Relates brain activity to predictors** using the **General Linear Model (GLM)**.  \n",
    "âœ… **Helps compute statistical contrasts** to find significant brain activations.  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. Structure of the Design Matrix**  \n",
    "The design matrix is a **2D matrix** where:  \n",
    "- **Rows** = Individual time points (or scans).  \n",
    "- **Columns** = Predictors (e.g., task conditions, motion parameters).  \n",
    "\n",
    "Each column represents a **regressor** that models a specific aspect of the data.  \n",
    "\n",
    "#### **Example: A Simple Block Design**\n",
    "| Time Point | Task | Rest | Motion X | Motion Y |\n",
    "|------------|------|------|---------|---------|\n",
    "| 1          | 1    | 0    | 0.2     | 0.1     |\n",
    "| 2          | 1    | 0    | 0.3     | 0.1     |\n",
    "| 3          | 0    | 1    | -0.1    | 0.2     |\n",
    "| ...        | ...  | ...  | ...     | ...     |\n",
    "\n",
    "**Key Components:**\n",
    "- **Condition Regressors** (e.g., \"Task\" vs. \"Rest\")  \n",
    "- **Nuisance Regressors** (e.g., motion parameters from the `rp_` file)  \n",
    "- **Drift Terms** (to model slow scanner drifts)  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. Visualization of the Design Matrix in SPM**  \n",
    "SPM provides a **graphical representation** of the design matrix.  \n",
    "- **Black/white blocks** show experimental conditions.  \n",
    "- **Gray-scale intensities** represent continuous regressors (e.g., motion parameters).  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. How is the Design Matrix Used?**  \n",
    "SPM fits the GLM:  \n",
    "\\[\n",
    "Y = X\\beta + \\epsilon\n",
    "\\]\n",
    "where:  \n",
    "- \\( Y \\) = fMRI data (BOLD signal at each voxel).  \n",
    "- \\( X \\) = Design matrix (predictors).  \n",
    "- \\( \\beta \\) = Regression coefficients (effect sizes).  \n",
    "- \\( \\epsilon \\) = Residual error.  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. Why is the Design Matrix Important?**  \n",
    "âœ… **Ensures valid statistical analysis** by properly modeling the experiment.  \n",
    "âœ… **Allows hypothesis testing** using contrasts (e.g., Task > Rest).  \n",
    "âœ… **Helps control confounds** like motion and scanner drifts.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2056066-8591-4bc6-b241-3d63aff95449",
   "metadata": {},
   "source": [
    "---\n",
    "In **SPM12**, the preprocessing steps for fMRI data are designed to prepare raw data for statistical analysis, ensuring that artifacts are minimized and data are aligned properly for analysis. Below are the key preprocessing steps commonly applied in SPM12:\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Realignment (Motion Correction)**\n",
    "- **Purpose**: Correct for head motion during the scanning session.\n",
    "- **How it works**: This step involves **aligning** all functional images to a reference image (typically the first or mean image) to account for small movements of the subject's head.\n",
    "- **Output**: Realigned images and realignment parameters (`rp_` file) containing translations and rotations (X, Y, Z, pitch, roll, yaw).\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Slice Timing Correction**\n",
    "- **Purpose**: Correct for differences in acquisition times between slices in each functional volume.\n",
    "- **How it works**: If slices are acquired non-sequentially (common in fMRI), slice timing correction adjusts for the time delays by resampling the data, ensuring that all slices are aligned temporally.\n",
    "- **Output**: Corrected data where the slices are aligned in time.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Coregistration**\n",
    "- **Purpose**: Align the **structural (anatomical) image** (e.g., T1-weighted) with the functional images.\n",
    "- **How it works**: The functional images are coregistered (i.e., spatially aligned) with the structural image to ensure that brain regions are in the same space across modalities.\n",
    "- **Output**: A coregistered functional image set aligned with the structural image.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Segmentation**\n",
    "- **Purpose**: Separate the structural image into different tissue types (gray matter, white matter, cerebrospinal fluid).\n",
    "- **How it works**: This step uses tissue probability maps to segment the anatomical image into its components.\n",
    "- **Output**: Tissue probability maps (gray matter, white matter, CSF) and normalized tissue images.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Normalization (Spatial Normalization)**\n",
    "- **Purpose**: Map individual subject data to a standard brain template (e.g., MNI space).\n",
    "- **How it works**: Functional and anatomical images are transformed to fit into a **common space** (e.g., Montreal Neurological Institute (MNI) space). This allows for group analyses by aligning brain structures across individuals.\n",
    "- **Output**: Normalized images in standard space (e.g., MNI or Talairach space).\n",
    "\n",
    "---\n",
    "\n",
    "### **6. Smoothing**\n",
    "- **Purpose**: Increase the signal-to-noise ratio (SNR) and make the data more Gaussian in distribution.\n",
    "- **How it works**: A **Gaussian filter** is applied to the images, smoothing the data spatially by averaging nearby voxel values. This step is essential for statistical inference, especially when performing group-level analysis.\n",
    "- **Output**: Smoothed functional images.\n",
    "\n",
    "---\n",
    "\n",
    "### **7. (Optional) Artifact Detection and Detrending**\n",
    "- **Purpose**: Detect and remove outliers or artifacts, such as motion spikes, or slow drift over time.\n",
    "- **How it works**: Various methods, such as **motion scrubbing** or **temporal filtering**, may be used to remove these artifacts from the data.\n",
    "- **Output**: Cleaned and artifact-free data.\n",
    "\n",
    "---\n",
    "\n",
    "### **8. (Optional) Temporal Filtering**\n",
    "- **Purpose**: Remove low- and high-frequency noise from the data.\n",
    "- **How it works**: A **bandpass filter** can be applied to focus on the frequencies of interest (e.g., 0.01-0.1 Hz for typical resting-state fMRI studies). This helps remove high-frequency noise and low-frequency drifts.\n",
    "- **Output**: Filtered data focused on the frequency range of interest.\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary of Typical Preprocessing Steps in SPM12**:\n",
    "1. **Realignment** â€“ Correct for head motion.\n",
    "2. **Slice Timing Correction** â€“ Adjust for slice acquisition timing differences.\n",
    "3. **Coregistration** â€“ Align functional and structural images.\n",
    "4. **Segmentation** â€“ Segment the structural image into tissue types.\n",
    "5. **Normalization** â€“ Transform images to a standard space (e.g., MNI).\n",
    "6. **Smoothing** â€“ Spatially smooth the functional data.\n",
    "7. **Artifact Detection/Detrending** (Optional) â€“ Remove outliers or slow drifts.\n",
    "8. **Temporal Filtering** (Optional) â€“ Remove noise in temporal data.\n",
    "\n",
    "---\n",
    "\n",
    "These preprocessing steps are typically followed by statistical modeling using the General Linear Model (GLM) in SPM to identify regions of the brain that are significantly activated during experimental tasks or conditions.\n",
    "\n",
    "Would you like further clarification on any of these steps? ðŸ˜Š\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda2fe5-8730-4d5f-9b71-ceacc2b48841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Design Matrix\n",
    "\n",
    "# Load the pre-processed data (Realigned, Slice-Time corrected, Co-Registerd, Normalized and Smoothed)\n",
    "# swar..sub-01_task-ft_run-1_bold.nii.gz\n",
    "# s = smoothed\n",
    "# w = normalized\n",
    "# a = STC\n",
    "# r = realigned\n",
    "\n",
    "fmri_file = 'sub-01/func/swarsub-01_task-ft_run-1_bold.nii.gz'\n",
    "f_img = nib.load(fmri_file)\n",
    "# Get the data\n",
    "f_img_data = f_img.get_fdata()\n",
    "\n",
    "# Generate the mean functional image. It will be used to superimpose the functional results.\n",
    "m_img = mean_img(f_img, copy_header=True)\n",
    "\n",
    "\n",
    "t_r = 2 #TR = 2\n",
    "n_scans = 200 #Number of scans = Experiment lenght = 400\n",
    "\n",
    "frame_times = np.arange(n_scans) * t_r #Time Frames\n",
    "\n",
    "# Definition of the different trials\n",
    "conditions = [\"B\", \"R\", \"B\", \"L\", \"B\", \"R\", \"B\", \"L\", \"B\", \"R\", \"B\", \"L\", \"B\", \"R\", \"B\", \"L\", \"B\", \"R\", \"B\", \"L\"]\n",
    "duration = [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]\n",
    "# these are the corresponding onset times\n",
    "onsets = [0.0, 20.0, 40.0, 60.0, 80.0, 100.0, 120.0, 140.0, 160.0, 180.0, 200.0, 220.0, 240.0, 260.0, 280.0, 300.0, 320.0, 340.0, 360.0, 380.0]\n",
    "# Next, we simulate 6 motion parameters jointly observed with fMRI acquisitions\n",
    "motion = motion_params\n",
    "# The 6 parameters correspond to three translations and three\n",
    "# rotations describing rigid body motion\n",
    "add_reg_names = [\"tx\", \"ty\", \"tz\", \"rx\", \"ry\", \"rz\"]\n",
    "\n",
    "\n",
    "events = pd.DataFrame({\"trial_type\": conditions, \"onset\": onsets, \"duration\": duration})\n",
    "\n",
    "# We include three drift regressors. Their aim is to remove signal components unrelated to the expected neural response.\n",
    "\n",
    "X1 = make_first_level_design_matrix(\n",
    "    frame_times, events, drift_model='polynomial', drift_order=3,\n",
    "    add_regs=motion, add_reg_names=add_reg_names, hrf_model=hrf_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ccd6f-8105-43bb-8b6a-67e00226d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_design_matrix(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d71662-f71e-467d-ade1-7b47cf53f09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the GLM\n",
    "fmri_glm = FirstLevelModel(\n",
    "    smoothing_fwhm=5,\n",
    "    minimize_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8426bd71-ad8f-4f2c-b0bd-2b13706c24d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the GLM\n",
    "fmri_glm = fmri_glm.fit(fmri_file, design_matrices=X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d892c-e6da-492b-846c-3ed7ee209d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Contrast\n",
    "n_regressors = X1.shape[1]\n",
    "activation = np.zeros(n_regressors)\n",
    "activation[1] = 1\n",
    "activation[2] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f68464-035e-4fed-9905-3979955df428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_contrast_matrix(contrast_def=activation, design_matrix=X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614035b-0642-4345-b43e-4a9b43b81bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the contrast\n",
    "eff_map = fmri_glm.compute_contrast(activation, output_type=\"effect_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0ea4b-70d3-4358-abad-3c2139e33cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the t statistics contrast\n",
    "t_map = fmri_glm.compute_contrast(activation, stat_type = \"t\", output_type=\"stat\")\n",
    "#z_map = fmri_glm.compute_contrast(activation, output_type=\"z_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5672ac-4545-4b6c-845c-f565dbed4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the activations\n",
    "cut_coords = [42, 40, 21]\n",
    "plotting_config = {\n",
    "    \"bg_img\": m_img,\n",
    "    \"display_mode\": \"z\", #Axial\n",
    "    \"cut_coords\": cut_coords,\n",
    "    \"black_bg\": True,\n",
    "}\n",
    "plot_stat_map(\n",
    "    t_map,\n",
    "    threshold=3,\n",
    "    title=\"right > left (|t|>5)\",\n",
    "    figure=plt.figure(figsize=(10, 4)),\n",
    "    **plotting_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbe66fe-92f9-4d96-83c7-7013ebd5eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the activations using the FDR control\n",
    "clean_map, threshold = threshold_stats_img(\n",
    "    t_map, alpha=0.05, height_control=\"fdr\", two_sided=False\n",
    ")\n",
    "plot_stat_map(\n",
    "    clean_map,\n",
    "    threshold=threshold,\n",
    "    title=(\n",
    "        f\"right > rest (p<0.05 FDR-corrected; threshold: {threshold:.3f})\"\n",
    "    ),\n",
    "    figure=plt.figure(figsize=(10, 4)),\n",
    "    **plotting_config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
